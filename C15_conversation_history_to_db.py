# âœ… è¼‰å…¥ LangChain æ‰€éœ€æ¨¡çµ„
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import SQLChatMessageHistory
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate
import sqlite3
from langchain.chains.summarize import load_summarize_chain
from langchain_core.documents import Document
from langchain_core.runnables import RunnableLambda
from operator import itemgetter

# âœ… åˆå§‹åŒ–æœ¬åœ°Ollamaæ¨¡å‹
llm = OllamaLLM(model="gemma3")

# âœ… å»ºç«‹ã€Œå°è©±æ‘˜è¦ã€çš„æç¤ºæ¨¡æ¿
# ğŸ” é€™æ®µ prompt æœƒåœ¨æ¯æ¬¡è¨˜æ†¶æ›´æ–°æ™‚ä½¿ç”¨ï¼Œå¹«æˆ‘å€‘æŠŠèˆŠæ‘˜è¦èˆ‡æ–°å°è©±ä¸€èµ·å‚³çµ¦æ¨¡å‹ï¼Œå†ç”±æ¨¡å‹è¼¸å‡ºæ–°çš„æ‘˜è¦
summary_prompt = ChatPromptTemplate.from_template(
    "é€™æ˜¯ç›®å‰çš„å°è©±æ‘˜è¦ï¼š\n\n{summary}\n\né€™æ˜¯æ–°çš„å°è©±å…§å®¹ï¼š\n\n{new_lines}\n\nè«‹ç”¨ä¸­æ–‡æ›´æ–°å°è©±æ‘˜è¦ï¼š"
)

# âœ… å»ºç«‹ã€Œæœƒè©±æµç¨‹ã€çš„å‡½å¼ï¼ˆæœƒæ ¹æ“šåŠ©ç†åç¨±å»ºç«‹è¨˜æ†¶èˆ‡æç¤ºï¼‰
def create_chain(assistant):
    # ğŸ” è¨­å®šèŠå¤©æç¤ºï¼šç³»çµ±è§’è‰² + æ­·å²å°è©± + ä½¿ç”¨è€…è¼¸å…¥
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", f"ä½ æ˜¯å€‹{assistant}ï¼Œè«‹æ ¹æ“šå°è©±ä½œå›æ‡‰"),
        MessagesPlaceholder(variable_name="history"),  # â¬…ï¸ æ’å…¥è¨˜æ†¶å…§å®¹
        ("human", "{input}")  # â¬…ï¸ æœ€æ–°è¼¸å…¥çš„è¨Šæ¯
    ])

    # ğŸ” å»ºç«‹ SQLite èŠå¤©è¨˜æ†¶è³‡æ–™åº«ï¼Œä¾æ“šåŠ©ç†åç¨±å„²å­˜æ¯æ®µå°è©±
    history_db = SQLChatMessageHistory(
        session_id=assistant,
        connection_string='sqlite:///historyMemory.db',
        table_name="chat_memory"
    )

    # ğŸ” ä½¿ç”¨ ConversationSummaryBufferMemoryï¼šå°‡èˆŠå°è©±è‡ªå‹•æ¿ƒç¸®æ‘˜è¦ï¼Œä¿ç•™æ ¸å¿ƒå…§å®¹
    memory = ConversationSummaryBufferMemory(
        llm=llm,
        prompt=summary_prompt,
        return_messages=True,
        chat_memory=history_db,
        max_token_limit=1000  # â¬…ï¸ å¯æ§åˆ¶æ‘˜è¦é•·åº¦ï¼ˆè¦–æ¨¡å‹æ”¯æ´åº¦èª¿æ•´ï¼‰
    )

    # ğŸ” åˆ¤æ–·æ˜¯å¦å·²ç¶“æœ‰æ‘˜è¦è¨˜æ†¶ï¼Œè‹¥æ²’æœ‰ä¸”æœ‰èˆŠå°è©±è¨˜éŒ„ï¼Œå‰‡ç¬¬ä¸€æ¬¡æ‰‹å‹•å»ºç«‹æ‘˜è¦
    current_summary = memory.load_memory_variables({}).get("history", "")
    if not current_summary:
        messages = history_db.messages
        if messages:
            summary_text = summarize_existing_history(messages)
            memory.moving_summary_buffer = summary_text  # â¬…ï¸ å¡«å…¥è¨˜æ†¶æ‘˜è¦
            print(f"ğŸ§  å¾æ­·å²è³‡æ–™ä¸­ç”¢ç”Ÿæ‘˜è¦å¦‚ä¸‹ï¼š\n{summary_text}\n")
        else:
            print("ğŸ§  å°šç„¡è¨˜æ†¶ç´€éŒ„ï¼Œé€™æ˜¯ä½ å€‘çš„ç¬¬ä¸€æ¬¡å°è©±ã€‚\n")

    return chat_prompt, memory

# âœ… é¡¯ç¤ºæ‰€æœ‰æ›¾ç¶“å»ºç«‹éè¨˜æ†¶çš„åŠ©ç†åç¨±
def list_assistants():
    conn = sqlite3.connect("historyMemory.db")
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT DISTINCT session_id FROM chat_memory")
        assistants = [row[0] for row in cursor.fetchall()]
    except sqlite3.OperationalError:
        assistants = []  # â¬…ï¸ è‹¥è¡¨æ ¼å°šæœªå»ºç«‹ï¼Œå›å‚³ç©ºé™£åˆ—
    conn.close()
    return assistants

# âœ… è‡ªè¨‚ä¸­æ–‡æ‘˜è¦çš„ Prompt æ¨¡æ¿
custom_stuff_prompt = PromptTemplate.from_template(
    "ä½ æ˜¯ä¸€å€‹å–„æ–¼ä¸­æ–‡ç¸½çµçš„åŠ©ç†ã€‚è«‹é–±è®€ä»¥ä¸‹å°è©±å…§å®¹ï¼Œä¸¦ç”¨ç¹é«”ä¸­æ–‡ç°¡è¦ç¸½çµå‡ºå°è©±çš„é‡é»ï¼š\n\n{text}\n\nç¹é«”ä¸­æ–‡æ‘˜è¦ï¼š"
)

# âœ… å°‡æ•´æ®µèˆŠå°è©±é€²è¡Œæ‘˜è¦ï¼ˆåªç”¨æ–¼ç¬¬ä¸€æ¬¡å»ºç«‹è¨˜æ†¶ï¼‰
def summarize_existing_history(messages):
    if not messages:
        return ""
    
    # ğŸ” å°‡æ­·å²è¨Šæ¯åˆä½µç‚ºæ–‡å­—ï¼Œæ¯å¥é–‹é ­åŠ ä¸Šè§’è‰²åç¨±
    text = "\n\n".join([f"{'ä½¿ç”¨è€…' if m.type == 'human' else 'åŠ©ç†'}ï¼š{m.content}" for m in messages])
    docs = [Document(page_content=text)]

    # ğŸ” ä½¿ç”¨ summarize chain åŠ ä¸Šæˆ‘å€‘è‡ªå®šçš„ç¹é«”ä¸­æ–‡æç¤º
    summarize_chain = load_summarize_chain(
        llm=llm,
        chain_type="stuff",
        prompt=custom_stuff_prompt
    )
    return summarize_chain.run(docs)

# âœ… ä¸»ç¨‹å¼é–‹å§‹ï¼ˆäº’å‹•å…¥å£ï¼‰
if __name__ == "__main__":
    # ğŸ” å…ˆåˆ—å‡ºç›®å‰æœ‰å“ªäº›å·²å„²å­˜çš„åŠ©ç†
    existing = list_assistants()
    if existing:
        print("ğŸ“‹ ç›®å‰å·²æœ‰è¨˜æ†¶çš„åŠ©ç†æœ‰ï¼š")
        for name in existing:
            print(f" - {name}")
    else:
        print("ğŸ“‹ ç›®å‰é‚„æ²’æœ‰ä»»ä½•è¨˜æ†¶ä¸­çš„åŠ©ç†ã€‚")

    # ğŸ” è®“ä½¿ç”¨è€…è¼¸å…¥è¦ä½¿ç”¨å“ªå€‹åŠ©ç†ï¼ˆé è¨­ç‚ºå°åŠ©ç†ï¼‰
    sys_msg = input('è«‹è¨­å®šåŠ©ç†åç¨±ï¼š')
    if not sys_msg.strip():
        sys_msg = 'å°åŠ©ç†'

    # ğŸ” å»ºç«‹å°è©±è¨˜æ†¶èˆ‡æç¤º
    chat_prompt, memory = create_chain(sys_msg)

    # ğŸ” é¡¯ç¤ºé€™ä½åŠ©ç†ç›®å‰çš„æ‘˜è¦è¨˜æ†¶ï¼ˆè‹¥æœ‰çš„è©±ï¼‰
    print(f"\nğŸ” æ­¡è¿å›ä¾†ï¼Œ{sys_msg}ï¼")
    summary_data = memory.load_memory_variables({}).get("history", [])
    if summary_data and isinstance(summary_data, list):
        summary_text = summary_data[0].content
        print(f"ğŸ§  ä¸Šæ¬¡çš„æ‘˜è¦è¨˜æ†¶å¦‚ä¸‹ï¼š\n{summary_text}\n")
    else:
        print("ğŸ§  å°šç„¡è¨˜æ†¶ç´€éŒ„ï¼Œé€™æ˜¯ä½ å€‘çš„ç¬¬ä¸€æ¬¡å°è©±ã€‚\n")

    # âœ… çµ„åˆæˆæœƒè©±éˆï¼ˆåŒ…å«è¨˜æ†¶ã€æç¤ºã€æ¨¡å‹ï¼‰ï¼Œä¸¦ä¸²æ¥ LCEL å…ƒä»¶
    chain = ConversationChain(
        llm=llm,
        memory=memory,
        prompt=chat_prompt,
        verbose=True
    ) | RunnableLambda(lambda x: {"response": x['response']}) | itemgetter("response")

    print()

    # âœ… ä½¿ç”¨è€…é–‹å§‹å°è©±ï¼ˆå¯ç”¨ /è¨˜æ†¶ã€/æ­·å² æŒ‡ä»¤ï¼‰
    while True:
        msg = input("æˆ‘èªªï¼š")
        if not msg.strip():
            break

        # ğŸ” è‹¥è¼¸å…¥ /è¨˜æ†¶ï¼Œå¼·åˆ¶é‡æ–°æ‘˜è¦å°è©±å…§å®¹
        if msg.strip() == "/è¨˜æ†¶":
            messages = memory.chat_memory.messages
            if messages:
                summary_text = summarize_existing_history(messages)
                memory.moving_summary_buffer = summary_text  # æ›´æ–°æ‘˜è¦è¨˜æ†¶
                print(f"\nğŸ§  å·²æ›´æ–°æ‘˜è¦è¨˜æ†¶å…§å®¹å¦‚ä¸‹ï¼š\n{summary_text}\n")
            else:
                print("\nğŸ§  (ç›®å‰å°šç„¡æ‘˜è¦è¨˜æ†¶)\n")
            continue

        # ğŸ” è‹¥è¼¸å…¥ /æ­·å²ï¼Œé¡¯ç¤ºæ‰€æœ‰æ­·å²å°è©±è¨Šæ¯
        if msg.strip() == "/æ­·å²":
            print("\nğŸ—‚ï¸ SQLite å°è©±æ­·å²ï¼š")
            for message in memory.chat_memory.messages:
                role = "ğŸ§‘â€ğŸ¦± ä½¿ç”¨è€…" if message.type == "human" else "ğŸ¤– åŠ©ç†"
                print(f"{role}ï¼š{message.content}")
            print()
            continue

        # ğŸ” ä¸€èˆ¬å°è©±æµç¨‹ï¼šå‚³å…¥è¼¸å…¥è¨Šæ¯ï¼Œå–å¾— AI å›æ‡‰
        response = chain.invoke({"input": msg})
        print(f'{sys_msg}ï¼š{response}\n')
